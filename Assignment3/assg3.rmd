---
title-meta: FINA5250 Assignment 3
author-meta: LIU, Weiyang
geometry: "left=1.25in,right=1.25in,top=1in,bottom=1in"
output: pdf_document
---

# Assignment 3
FINA 5250 Empirical Methods in Finance

LIU, Weiyang

[wliuax@connect.ust.hk](mailto:wliuax@connect.ust.hk)

```{r setup, include = TRUE, echo = FALSE}
# set working directory
setwd("d:/workspace/FINA5250/Assignment3")
# remove all objects from the current workspace
rm(list = ls())
```

```{r, echo = FALSE}
# load data
goog <- read.table("Google.csv", sep = ",", header = TRUE)
```

## Question 1
```{r, echo = FALSE}
lm_1 <- lm(rGoog_ex ~ rM_ex, data = goog)
summary(lm_1)
```

## Question 2
### 2.1
Yes. $\beta$ is significantly different from 0 at 0.1\% level.

### 2.2
No. It is significant at 10\% level but not at 5\% level.

### 2.3
No. Let's find the 95\% confidence interval of $\beta$.
```{r, echo = FALSE}
beta_summary <- summary(lm_1)$coefficients["rM_ex", ]
beta_lo <- beta_summary[1] - 2 * beta_summary[2]
beta_hi <- beta_summary[1] + 2 * beta_summary[2]
cat(sprintf("Lower bound: %s\n", beta_lo))
cat(sprintf("Upper bound: %s\n", beta_hi))
if (beta_lo > 1 || beta_hi < 1) {
  cat("The confidence interval doesn't include 1\n")
} else {
  cat("The confidence interval includes 1\n")
}
```
Therefore, we cannot say beta is significantly different from 1.

## Question 3
```{r, echo = FALSE}
lm_3 <- lm(rGoog_ex ~ rM_ex + rSmB + rHmL, data = goog)
summary(lm_3)
```

## Question 4
As a whole, the factors are significant, because the p-value of F-statistic is smaller than 0.05.

Individually, all factors are significant as well (p < 0.05).

## Question 5
```{r, echo = FALSE}
cat(sprintf("The single factor can explain %.2f%% of the variation\n",
            summary(lm_1)$r.squared * 100))

cat(sprintf("The three factors can explain %.2f%% of the variation\n",
            summary(lm_3)$r.squared * 100))
```

## Question 6
```{r, echo = FALSE}
anova(lm_1, lm_3)
```
Yes, the 3-factor model explains significantly more variation (p < 0.05).

## Question 7
```{r, echo = FALSE}
goog_train <- head(goog, 100)
goog_test <- tail(goog, 75)

lm_1_train <- lm(rGoog_ex ~ rM_ex, data = goog_train)
summary(lm_1_train)

lm_3_train <- lm(rGoog_ex ~ rM_ex + rSmB + rHmL, data = goog_train)
summary(lm_3_train)
```

```{r, echo = FALSE}
y_pred_1 <- predict.lm(lm_1_train, newdata = goog_test)
y_pred_3 <- predict.lm(lm_3_train, newdata = goog_test)

mean_y_train <- mean(goog_train$rGoog_ex)

rsquared_test <- function(y, y_pred, mean_y_train){
  sse <- sum((y_pred - y)^2)
  tss <- sum((y - mean_y_train)^2)
  return(1 - sse / tss)
}

cat(sprintf("Out-of-sample R-squared of the single-factor model is %s\n",
            rsquared_test(goog_test$rGoog_ex, y_pred_1, mean_y_train)))

cat(sprintf("Out-of-sample R-squared of the three-factor model is %s\n",
            rsquared_test(goog_test$rGoog_ex, y_pred_3, mean_y_train)))
```

The three-factor model explains even less variation than the single-factor model in the testing set, so the single-factor model is better in this case.
